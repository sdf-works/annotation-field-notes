# FIELD NOTE 3 — Observation Changes the System

In quantum mechanics, observation changes the system. Anthropologists have known a parallel truth for decades: watching human behavior alters the behavior being watched.

What’s startling is how clearly this applies to LLM development, and it seems like the industry hasn’t metabolized the implication yet.

When we create human-behavior datasets for training, we pretend we’re capturing something raw, natural, unaltered. But the moment a human knows they’re being recorded, 
evaluated, paid, or judged, the signal shifts. The “data” stops being behavior and instead becomes performed behavior, shaped by incentives, surveillance, 
fear of being wrong, desire to please, desire to trick, or simply fatigue.

From the inside, the effect is obvious. The observed system bends around the act of being observed.

The result:
- The dataset contains noise introduced by the observation itself, not the underlying phenomenon.
- The model learns from the distorted version.
- And then we call that distortion “human behavior.”

For AI safety, this is a foundational issue. We are training systems to emulate the shadow cast by observation, not the unobserved mind underneath.

The next field notes will break down specific examples of how this distortion happens in live annotation environments and how it shapes models in ways we rarely acknowledge.
